Timestamp,Your Name,Paper Title,List of Authors,Venue,Short Description,Paper URL,Study URL,ReVISit Version,Source Code Link,Email Address,Study Type,Has this paper been published?,Date of Publication
10/1/2024 11:09:37,Max Lisnic,Visualization Guardrails: Designing Interventions Against Cherry-Picking in Interactive Data Explorers,"Maxim Lisnic, Zach Cutler, Marina Kogan, Alexander Lex",ACM CHI,"The rise of interactive time series exploration platforms has made it easier for the general public to visualize data related to public interest, while also facilitating the creation of misleading visualizations through cherry-picked data. This study explores the potential of visualization design to combat cherry-picking—a common tactic used to misrepresent data—by developing a design space of guardrails aimed at discouraging this practice. Through crowd-sourced experiments, the researchers evaluate the effectiveness of these guardrails.",https://vdl.sci.utah.edu/publications/2025_chi_guardrails/,https://vdl.sci.utah.edu/viz-guardrails-study/,1.0.0,https://github.com/visdesignlab/viz-guardrails-study,u1317463@gcloud.utah.edu,"Visual Encoding, Visualization Technique",No,2024
10/1/2024 12:14:39,Ishrat Jahan Eliza,Accessible Text Descriptions for UpSet Plots,"Andrew McNutt, Maggie McCracken, Ishrat Jahan Eliza, Daniel Hajas, Jake Wagoner, Nate Lanza, Jack Wilburn, Sara Cream-Regehr, Alexander Lex",EuroVis,"In our paper, we generate human readable Text Description for UpSet Plots and we use ReVISit to evalute user experience with the generated text description. We used the tool for survey in Prolific. ",https://vdl.sci.utah.edu/publications/2025_eurovis_text-descriptions/,https://vdl.sci.utah.edu/Upset-alttxt-study/,1.0.2,https://github.com/visdesignlab/Upset-alltx-study,elizaan199834@gmail.com,Survey,No,2024
10/1/2024 13:16:11,Zach Cutler,Crowdsourced Think-Aloud Studies,"Zach Cutler, Lane Harrison, Carolina Nobre, Alexander Lex",ACM CHI,"We ran two studies with revisit. The first study showed participants a few interactive charts and had them answer questions about the data, and the second showed participants static visualizations with associated captions and asked them if they trusted the data. ",https://vdl.sci.utah.edu/publications/2025_chi_crowdaloud/,https://vdl.sci.utah.edu/ThinkAloud/,1.0.0,https://github.com/visdesignlab/ThinkAloud,zach.t.cutler@gmail.com,"Interaction, Think-Aloud",No,2024
10/2/2024 21:07:36,Yiren Ding,Promises and Pitfalls: Using Large Language Models to Generate Visualization Items,"Yuan Cui, W Ge Lily, Yiren Ding, Lane Harrison, Fumeng Yang, Matthew Kay",IEEE Transactions on Visualization and Computer Graphics,"This paper investigates the potential for large language models (LLMs) to automate the generation of multiple-choice visualization items. We develop the VILA
(Visualization Items Generated by Large LAnguage Models) pipeline, for efficiently generating visualization items that measure people’s ability to accomplish visualization task.",https://osf.io/au3er/download,,1.0.0,,dyr429@gmail.com,Survey,Yes,2024-09-10