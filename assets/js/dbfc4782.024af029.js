"use strict";(self.webpackChunkdocs_website=self.webpackChunkdocs_website||[]).push([[8749],{91895:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025/01/20/release-2.0","metadata":{"permalink":"/blog/2025/01/20/release-2.0","source":"@site/blog/2025-01-20-release-2.0.md","title":"ReVISit v2.0: Making your Studies even more Powerful!","description":"It\'s the start of a new year and we\'re excited to announce the release of reVISit v2.0 \u2014 just in time for your VIS 2025 submissions! We\'ve been working hard to bring you a new and improved version of reVISit, and we can\'t wait for you to try it out.","date":"2025-01-20T00:00:00.000Z","tags":[],"readingTime":5.37,"hasTruncateMarker":false,"authors":[{"name":"The ReVISit Team","key":"team","page":null}],"frontMatter":{"layout":"post","title":"ReVISit v2.0: Making your Studies even more Powerful!","authors":["team"]},"unlisted":false,"nextItem":{"title":"ReVISit v1.0: Taking Control of Your Online Studies!","permalink":"/blog/2024/06/20/release-1.0"}},"content":"It\'s the start of a new year and we\'re excited to announce the release of reVISit v2.0 \u2014 just in time for your VIS 2025 submissions! We\'ve been working hard to bring you a new and improved version of reVISit, and we can\'t wait for you to try it out.\\n\\nThere are a lot of new features in this release, so let\'s dive in and take a look at what\'s new:\\n\\n## Feature Highlights\\n\\n### Participant Replay\\n\\nEver wondered where your participants clicked when they completed your study? We\'ve enabled participant replays, so you can now replay the interactions of participants in your studies during analysis. This enables you to see how participants are interacting with your study, either **to discover issues in a pilot**, or to actually **analyze interaction behavior**.\\n\\n<iframe width=\\"100%\\" height=\\"450\\" src=\\"https://www.youtube.com/embed/wjP35gra9J4?si=aNkDA-uN2U7ryVeu\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nCheck out the [demo](https://revisit.dev/study/example-brush-interactions/VTJGc2RHVmtYMS9Qbm9DalhDeS81NVFkamZ1dm11NW41c0hwZUM5ZnZ3UT0=?participantId=8a8aa43e-9914-459e-b0ed-078e28f34504) and the [documentation](https://revisit.dev/docs/analysis/participant-replay/). To enable replay, your study stimulus has to [track provenance](https://revisit.dev/docs/designing-studies/provenance-tracking/).\\n\\n### Vega and Vega-Lite Support\\n\\nWe\'ve added compatibility for [Vega](https://vega.github.io/vega/) and [Vega-Lite](https://vega.github.io/vega-lite/) visualizations as a component type, so you can now include these types of visualizations in your studies, leveraging the power of the reVISit platform. We also support tracking interactions in Vega visualizations, enabling you to inspect and analyze how participants used your stimulus with the aforementioned participant replay.\\n<iframe width=\\"100%\\" height=\\"450\\" src=\\"https://www.youtube.com/embed/_fIrIEidN54?si=9DMpeAcTdvhLETLN\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nCheck out the [demo](https://revisit.dev/study/demo-vega/), and [example of a replay](https://revisit.dev/study/demo-vega/VTJGc2RHVmtYMThjdTNyZXJobjdaSTlUVWpDb3NVckVXbmxNbFR6aWpXRT0=?participantId=6d9b3732-9c90-456e-a22b-652a562bf2e4) and the [documentation](https://revisit.dev/docs/designing-studies/vega-stimulus/).\\n\\n### Recording Participant Audio\\n\\nWe\'ve added support for recording participant audio, enabling you to run **think-aloud studies**\u2014even in crowdsourced settings. This is a great way to gain insight into participants\' thought processes and decision-making strategies and represents our latest effort to support qualitative research in reVISit. Audio recordings are automatically transcribed and part of your regular data download. You can even listen to the audio while watching the interactions of your participants [play out](https://revisit.dev/study/test-audio/VTJGc2RHVmtYMS8rS2dYblRlZDFOVmVrNjRWRVRjKzVTWGhPZzhkb1lzND0=?participantId=04eac92d-9892-4688-8bcc-15cf95145d9b).\\n<iframe width=\\"100%\\" height=\\"450\\" src=\\"https://www.youtube.com/embed/YNXIn-1qsk8?si=cvGRFDna8eJYlKN6\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nCheck out the [demo](https://revisit.dev/study/demo-vega/) and the [documentation](https://revisit.dev/docs/designing-studies/vega-stimulus/).\\n\\n### Libraries \\n\\nShould we test for color blindness? What are our participants\u2019 visualization literacy scores? How do participants rate the aesthetics of a visualization? We commonly ask these and similar questions, and often we use validated existing forms or methodologies to answer them. Re-implementing components is time-consuming and error prone. To address this, we\'ve added support for **libraries**, so you can leverage prebuilt study components to create your own studies. \\n\\nLibraries can save time and effort when creating studies, as you can reuse components that have already been created by others. You can also share your own components with the community by creating your own library and submitting a pull request.\\n<iframe width=\\"100%\\" height=\\"450\\" src=\\"https://www.youtube.com/embed/r95GZKwU5go?si=6Ea1JGdUw7XEgwDD\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nAt launch, we have implemented [nine libraries, ranging from simple checks, to questionnaires, to visualization literacy tests](https://revisit.dev/docs/category/libraries/). Check out the [demos](https://revisit.dev/study/?tab=Libraries) and the [documentation](https://revisit.dev/docs/designing-studies/plugin-libraries/).\\n\\n### Python Bindings\\n\\nWriting JSON can be difficult. Who wants to deal with a study config with 20,000 lines? To make it easier to create large and complex studies, we\'ve implemented Python bindings for the reVISit spec,  reVISitPy, that allow you to interact with reVISit programmatically. Here\u2019s a [basic example ](https://github.com/revisit-studies/revisitpy-examples/blob/main/example_simple_html/example_simple_html.ipynb) of how that works. \\n\\nThere are many promising things you can do with reVISitPy: \\n\\nFirst, we implemented a widget that lets you **run the study you created from inside the Jupyter notebook**. Now you have a fast way of inspecting experiments, randomization, etc. \\n\\nNext, you can **run through the study and download the data you generated straight into your notebook**, so that you can immediately see whether you\u2019re actually collecting all the data you need, and even pilot your analysis! \\n\\n<iframe width=\\"100%\\" height=\\"450\\" src=\\"https://www.youtube.com/embed/8Nad_oSNgKY?si=uTfbBtN-fmMx_wvZ\\" title=\\"YouTube video player\\" frameborder=\\"0\\" allow=\\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\\" referrerpolicy=\\"strict-origin-when-cross-origin\\" allowfullscreen></iframe>\\n\\nFinally, with the Python bindings we also enable you to design arbitrarily complex studies from **permutations**. What does that mean? Say, you have a stimulus, such as a scatterplot, that can render any compatible dataset, and you want to test how good participants are at judging correlations. You might want to feed in hundreds of different datasets that you\u2019re automatically generating. If you were to do this in the reVISit JSON spec, it would be very painful, because you have to create components for every single stimulus. In reVISitPy, it\u2019s just a few lines of code. And of course, this isn\u2019t limited to passing data into a component, you can premute over tasks, visual stimuli, or even phrasings of your questions, etc. \\n\\nCheck out the [documentation](https://revisit.dev/docs/revisitpy/), the [examples](https://github.com/revisit-studies/revisitpy-examples), and the [reVISitPy repository](https://github.com/revisit-studies/revisitpy) to learn more about how to use it. \\n\\n## Other Features / Changes\\n\\n- **Improved User Interface**: We\'ve redesigned the user interface to make it more intuitive and user-friendly. You\'ll find it even more pleasant to use, with a cleaner and more modern look.\\n- **Forms** have gotten some attention. See the [demo](https://revisit.dev/study/demo-survey/) and the [documentation](https://revisit.dev/docs/designing-studies/forms/): \\n   * We introduced new matrix form elements, which are useful if you want to ask e.g., Likert questions for many different items.  \\n   * Forms look nicer after an aesthetics overhaul.\\n   * We introduced dividers to section forms.\\n   * You can allow \u201cI don\u2019t know\u201d as an option for most form elements.\\n   * You can allow \u201cOther\u201d options for checkboxes and radios.\\n   * You can choose horizontal and vertical layouts for checkboxes and radios.\\n* You can now [design trainings](https://revisit.dev/docs/designing-studies/answers-trainings/)\\nwhere participants can validate answers \\n* Data export has improved, including things like participant numbers, clean time (time on task minus task where the browser tab was not active), etc. \\n\\nThese new features represent several months of work from the reVISit team, and we\u2019re excited to share them with the community. We\u2019re aiming to make reVISit more versatile, powerful, and easy to use. As always, we welcome your feedback and ideas for how we can support new directions for research in visualization and interactive systems. The best way to get in touch is to join our [Slack Team](https://join.slack.com/t/revisit-nsf/shared_invite/zt-25mrh5ppi-6sDAL6HqcWJh_uvt2~~DMQ)!\\n\\nWe\u2019re also ready to go on the road and meet you at your institution, or offer a virtual workshop! We recently visited Georgia Tech\u2019s GVU center to give a hands-on overview of reVISit. Catch our upcoming workshop at [CHI in Japan](https://chi2025.acm.org/). **Please reach out if you\u2019re interested in learning more about reVISit or potentially hosting a workshop.**"},{"id":"/2024/06/20/release-1.0","metadata":{"permalink":"/blog/2024/06/20/release-1.0","source":"@site/blog/2024-06-20-release-1.0.md","title":"ReVISit v1.0: Taking Control of Your Online Studies!","description":"Diagram of the revisit workflow. The study specification and components are used to compile an interactive, web-based study. As participants complete the study data is stored in Firebase and can be downloaded as tabular or JSON files, for subsequent analysis in analytics tools.","date":"2024-06-20T00:00:00.000Z","tags":[],"readingTime":6.96,"hasTruncateMarker":false,"authors":[{"name":"The ReVISit Team","key":"team","page":null}],"frontMatter":{"layout":"post","title":"ReVISit v1.0: Taking Control of Your Online Studies!","authors":["team"]},"unlisted":false,"prevItem":{"title":"ReVISit v2.0: Making your Studies even more Powerful!","permalink":"/blog/2025/01/20/release-2.0"}},"content":"[![Diagram of the revisit workflow. The study specification and components are used to compile an interactive, web-based study. As participants complete the study data is stored in Firebase and can be downloaded as tabular or JSON files, for subsequent analysis in analytics tools.](https://vdl.sci.utah.edu/assets/images/posts/2024-06-20_revisit-overview.png)](https://vdl.sci.utah.edu/assets/images/posts/2024-06-20_revisit-overview.png)\\n\\n<br />\\n\\nYou might have heard of **[reVISit](https://revisit.dev/)** before from [our paper](https://vdl.sci.utah.edu/publications/2023_shortpaper_revisit/), or you might have [seen a talk or participated in a meetup](https://revisit.dev/community/#community-activities). But as of today, we\u2019re excited to give the community a chance to run your own studies with reVISit with our 1.0 release \u2013 and CHI is just around the corner! \\n\\n## What is reVISit? \\n\\nReVISit is a software framework that enables you to [assemble experimental stimuli and survey questions into an online user study](https://revisit.dev/docs/getting-started/how-does-it-work/). \\nOne of the biggest time-saving features of ReVISit is a JSON grammar, the **reVISit Spec**, used to describe the setup of your study. \\nStimuli are contained in components and can be either markdown, images, web pages, React components, or survey questions. \\nThe figure at the top shows the relationship of the reVISit Spec, the components, and how they are then compiled into a study. \\n\\nDue to the different types of components, you can use reVISit for a diverse set of studies, spanning simple surveys, image-based perceptual experiments, and experiments evaluating complex interactive visualizations. \\n\\nReVISit is designed to accommodate sophisticated stimuli and study designs. Suppose you want to [replicate the seminal Cleveland and McGill study](https://revisit.dev/study/demo-cleveland/). With reVISit you could implement a React-based set of visualizations (a bar chart, a stacked bar chart, a pie chart), and then pass parameters, such as the data, and the markers to highlight the marks, all via the study configuration. \\n\\nSimilarly, the reVISit spec enables designers to create [controlled sequences](https://revisit.dev/docs/designing-studies/study-sequences/) defining in which order participants see stimuli. reVISit supports fixed, random, and Latin square designs that can be nested at various levels. For example, the overall study sequence (intro, training, experiment, survey) could be fixed. In the experiment arm, two conditions could use a Latin-square design. Within each condition, the experiment could randomly draw a small number of stimuli from a large stimuli pool while interspersing attention checks at random points and adding breaks. \\n\\n### Assembling and Deploying your Study\\n\\nThe components and your study configuration are then used to [assemble a web-based study](https://revisit.dev/docs/getting-started/your-first-study/). You can first look at your study on your local browser, and if you want to share it deploy it to the web server of your choice. We [recommend and document deploying to GitHub pages](https://revisit.dev/docs/data-and-deployment/deploying-to-static-website/), but any web server you have access to will do.   \\n\\nYou can then use the online version to direct participants to your study. You can use crowdsourcing platforms such as Prolific, Mechanical Turk or LabintheWild, or you can simply send a link to participants that you have recruited in other ways. \\n\\n### Data Collection \\nA typical study will have response fields, such as a text field or a slider, to provide the response. Such form-based responses are tracked by reVISit by default and can be downloaded in either JSON or a tidy tabular format. Similarly, you can provide [response data out of interactive stimuli](https://revisit.dev/docs/designing-studies/html-stimulus/). For example, if a task is to click on a specific bar in a bar chart, you can log which bars were clicked. ReVISit tracks a diverse set of browser window events such as mouse moves, clicks, scrolls, resizes, which are time-stamped and can hence be used for basic log file analysis. \\n\\nReVISit also supports advanced provenance tracking based on [trrack](https://apps.vdl.sci.utah.edu/trrack) a provenance tracking library  developed at our lab. If you instrument your study stimuli with trrack, you can recreate every state of your interface of every single participant! This can be incredibly useful to [understand nuances of user behavior](https://vdl.sci.utah.edu/publications/2021_chi_revisit/), as well as to help you debug your stimuli by exploring what went wrong in a particular session. In a future release, reVISit will also allow you to dynamically browse these events and fully \u201cre-hydrate\u201d all participants experiments. \\n\\n### Data Storage\\n\\nReVISit is implemented as a (mostly) server-less application, meaning that you don\u2019t have to run, secure, and maintain a server to use reVISit. The only exception to this is data storage, as obviously, the data of online participants has to be stored somewhere. \\n\\nIf you\u2019re running a local study, you can get away without this \u2013 you can just download the data from your browser after a study is complete. For online studies, we use Google Firebase to store data.\\n\\nCurrently, [setting up Firebase for a reVISit study](https://revisit.dev/docs/data-and-deployment/firebase-setup/) might be the most challenging part of working with reVISit. On the plus side, Firebase is a tried-and-true system where you have full control over your data. You even have options to choose the locale of your server so that you are compliant with your country\'s regulations on data storage. \\n\\n### Data Analysis\\n\\nReVISit is not meant to replace your usual data analysis approaches. Instead, it aims to make it easy to export data in the formats you might use in R, Python, or your analysis platform of choice. \\n\\nReVISit, however, does provide a basic [analytics interface](https://revisit.dev/docs/analysis/) that is most useful for monitoring the progress of your study. You can also use reVISit to identify participants that didn\u2019t appropriately complete the study and reject them, which is most useful if you want to ensure that you have appropriate numbers of participants in your Latin square design. \\n\\n## What are the Benefits of Using reVISit? \\n\\nSo, why would you use reVISit over other approaches to running your study, such as Qualtrics, Survey Monkey, or even a custom experiment interface? \\n\\nFirst, **reVISit is open source** with all the benefits you have of using open source software: it\u2019s free; you can extend it; you can contribute to improving it. \\n\\nSecond, the open source nature and our approach of forking reVISit for your own study and storing your data in your own Firebase means that **you have full control over your study and the data**. Once you have forked the study, it will remain accessible and unchanged for as long as you like. \\n\\nThird, reVISit has dedicated modes for **quickly navigating your study**, and you can also turn off data collection. This is great for both, developing your study, but also sharing your study with reviewers and readers of your research. That means that readers can see **exactly** what your participants saw, and hence may trust your study more. They could also fork your study and run a **replication of your study** with minimal effort! You can check out an [example study and the associated results.](https://vdl.sci.utah.edu/viz-guardrails-study/) \\n\\n## I\u2019m Intrigued, but Can I Trust it for my Experiment? \\n\\nreVISit is new, and we know that it\u2019s fraught to bet on a new project if you don\u2019t know whether it actually works or whether it will be maintained down the line. But we hope we can convince you to trust us! \\n\\nFirst, we currently have multiple years of funding to continue development of reVISit. \\nWe\u2019ve also ourselves run several successful studies, such as [a study on guardrails against misinformation](https://vdl.sci.utah.edu/viz-guardrails-study/). Finally, we are committed to help you out if you run into issues! Join our [slack team](https://join.slack.com/t/revisit-nsf/shared_invite/zt-25mrh5ppi-6sDAL6HqcWJh_uvt2~~DMQ) to get low-friction help, or write to us at [contact@revisit.dev](mailto:contact@revisit.dev). We\u2019re also happy to set up a meeting to answer any questions you may have; for example, to talk us through whether reVISit will work for your study design. \\n\\n\\n## How Can I Learn More or Get Involved? \\n\\nWe\u2019re grateful to all the community members who have shared their study needs and helped to make ReVISit 1.0 a reality, and we\u2019re looking forward to bringing the community exciting new features in the coming year. Future releases will include better debugging tools through study rehydration, a way to capture and code think-aloud data, and improved analysis capabilities. Depending on community feedback we\'re also interested in branching out to unconventional display devices (phones, AR/VR, etc.)\\n\\nTo take your first steps with reVISit, check out our [getting started guide](https://revisit.dev/docs/getting-started/) for instructions on how to install our software and to build a study.\\n\\nFinally, if you are missing a feature or find a bug, let us know! Since reVISit is completely open source you could even submit a pull request!\\n\\n## Acknowledgements\\n\\nWe are very grateful to everyone who helped make reVISit a reality, including our wonderful [community advisory board](https://revisit.dev/community/#community-advisory-board) and the [National Science Foundation for generous funding](https://vdl.sci.utah.edu/projects/2022-nsf-revisit/)."}]}}')}}]);